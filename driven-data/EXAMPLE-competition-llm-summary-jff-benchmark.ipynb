{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Howdy! This is a post with code that builds a benchmark for our [What's Up, Docs? Document Summarization with LLMs](https://www.drivendata.org/competitions/297/whats-up-docs/) practice competition.\n",
    "\n",
    "You're likely here because you've heard about Large Language Models (LLMs) and maybe you've used them some in the past, but you're interested in see how they can be used programmatically to solve problems that might be important to you. Let's get our feet wet.\n",
    "\n",
    "The goal of this competition is to build a computer program that will summarize long English documents for us. What makes for a good summary?\n",
    " - It should be coherent English.\n",
    " - It should be shorter than the document it's summarizing.\n",
    " - It should never be longer than a page or two.\n",
    " - It should capture the important content of the document at a high level.\n",
    " - It should exclude very specific details that don't affect the overall understanding of the document.\n",
    " - It should only include information from the document. (Don't do original research!  Don't make things up!)\n",
    "\n",
    "To make sure your summaries meet all these requirements, we've hired three full-time staffers to read all your summaries and provide grades based on the following rubric...\n",
    "\n",
    "Wait, no, nevermind. We're not doing that. A computer is going to grade them. How? By making sure the summaries you write look like summaries that other humans have already written. Doesn't that mean if the humans did a bad job, the scoring computer will reward doing a bad job? Why yes, [yes it does](https://www.xkcd.com/1838/).\n",
    "\n",
    "For this competition, we'll be using a dataset of academic papers from social science fields. This is not a group of people known for their concise, accessible writing. Can you model the strained brain of university professor forced to compress their last twelve months of nuanced thinking into a single paragraph (while weeping and gnashing their teeth)?\n",
    "\n",
    "We're [not the first](https://en.wikipedia.org/wiki/Automatic_summarization#History) to write a program like this. We're not the first to [use LLMs](https://paperswithcode.com/task/text-summarization) for this task. But the goal here is to learn, so those are good things! Let's tippy toe into the shallows. You'll be drowning in [arxiv papers](https://arxiv.org/list/cs.CL/recent) in no time! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Our approach in this benchmark will be to use a pretrained generative language model to write summaries for us. \"Language model\" means we'll use a program that has some understanding of the structure of human language. \"Generative\" means it writes all by itself. \"Pretrained\" means we'll use a program someone else already taught to speak English. If you're not suffering from terminology overload, \"autoregressive\" and \"instruction-tuned\" are some other relevant buzzwords.\n",
    "\n",
    "LLMs are big and can't be run on most regular-person computers, so the [biggest](https://ai.google.dev/gemini-api/docs) [and](https://openai.com/api/) [best](https://docs.anthropic.com/en/api/getting-started) are mostly available as APIs that cost money to use. That's unfortunate if you're just trying to learn, so to get started, we'll use a simpler model that can run locally on a normal computer.\n",
    "\n",
    "In this instance, we'll use a model called [Gemma 3](https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf). While LLM sizes typically start around 7 billion parameters and go up to *trillions*, the model that we're using, the smallest version Gemma 3, has \"only\" 1 billion parameters. If each parameter is a ping pong ball, we're talking about filling a modern art museum instead of something larger than the [Burj Khalifa](https://en.wikipedia.org/wiki/Burj_Khalifa). (What's a \"parameter\"? Did you ever learn the formula for a line, $y=mx+b$? $x$ is an input, $y$ is an output, and $m$ and $b$ are the **parameters**. $x$ and $y$ tell you *where* you are on the line, but $m$ and $b$ tell you *what* line you're on. Different parameters give you different lines, and similarly, different parameters give you different models.)\n",
    "\n",
    "As this is just meant to get you started, we'll get the model setup, ask it to generate some summaries for us, submit them to the platform, and see our scores. At the end we'll list some of the bells and whistles and beautiful pieces of flair you could adorn your approach with if you want to take it further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### LLM Server\n",
    "\n",
    "Getting an LLM running on you laptop has come a long way pretty quickly. One of the most popular tools for doing this, and the tool we'll be using, is called [Ollama](https://ollama.com/).\n",
    "\n",
    "To summarize [their instructions](https://github.com/ollama/ollama?tab=readme-ov-file#ollama) (which will require using the command line):\n",
    "\n",
    "1. Download [Ollama](https://ollama.com/download) to your computer and install it. This should be fairly quick because it doesn't actually include any models in the download.\n",
    "2. Download the model and run the server from the command line: `ollama run gemma3:1b`. This model is 815MB, so it might take a little while to download and start.\n",
    "\n",
    "Running that `ollama run` command does a few of nice things for us. First, it downloads the model weights (shorthand for \"parameters\") for us if we don't have them already. Second, it starts a chat interface on the command line for us. This is nice to quickly test if the model is working, and start chatting to get a feel for how this model communicates. Third, it starts up a server that allows us to communicate with the model using an [OpenAI-compatible API](https://github.com/ollama/ollama/blob/main/docs/openai.md). This API is how we'll work with the model from Python code. Which brings us to...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Python Environment\n",
    "\n",
    "A good practice when starting a new coding project is to make sure it doesn't interfere with any other projects you already have on your computer (think library version conflicts and all the other potential conflicts that cast off reams of inscrutable error messages as the gears grind and mash.)\n",
    "\n",
    "There are a number of tools for this (you might have seen [Anaconda](https://www.anaconda.com/docs/getting-started/miniconda/main#miniconda-latest-installer-links)). For this benchmark, we'll be using [`uv`](https://docs.astral.sh/uv/).\n",
    "\n",
    "1. Get `uv` [installed](https://docs.astral.sh/uv/getting-started/installation/) on your computer.\n",
    "2. Install the dependencies: `uv pip install numpy pandas requests seaborn tiktoken scikit-learn tqdm openai`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "\n",
    "All the data you'll need for this competition are on the [data download page](https://www.drivendata.org/competitions/297/competition-llm-doc-summarization/data/).\n",
    "\n",
    "* **Training Documents**: These are the papers and abstracts that you can use for building a summarizer. We'll look at these in a minute.\n",
    "* **Test Documents**: These are the papers for which you should make summaries. We **don't** give you the abstracts for these.\n",
    "* **Submission Format**: This file serves as an example for how to format your submission. It contains the necessary index and columns. Your submission to the leaderboard must be in this exact format (with different prediction values) in order to be scored successfully!\n",
    "* **Attribution**: This file lists all the paper titles, authors, and links for all the papers used in this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from textwrap import fill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import tiktoken\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from textwrap import fill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import tiktoken\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_SERVER = \"http://localhost:11434\"\n",
    "MODEL = \"gemma3:1b\"\n",
    "DATA_DIR = Path.cwd().parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCI...</td>\n",
       "      <td>In this article, Victor Fan argues that analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>## 1. Introduction\\n\\n\\nAn Electronic Health R...</td>\n",
       "      <td>Problem definition: Physicians spend more than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>## Introduction\\n\\n\\nTranslation  plays  an  i...</td>\n",
       "      <td>Literary translation is one of the most challe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>## 1 Problem Setup\\n\\n\\nRecent political scien...</td>\n",
       "      <td>There is a long-running debate on evaluating f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>## INTRODUCTION\\n\\n\\nThis  article  investigat...</td>\n",
       "      <td>Recently, ‘bimajyo’ (美魔女) came into focus in J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>## Methods\\n\\n\\n\\n## Sample\\n\\n\\nOur data come...</td>\n",
       "      <td>Demand for democratic accountability in polici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>## Introduction\\n\\n\\nCanada is a high-income c...</td>\n",
       "      <td>Canada’s employment standards laws and mandato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>## Introduction\\n\\n\\nCultural studies has ofte...</td>\n",
       "      <td>Cultural studies has often favoured a Foucauld...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>## 1. Introduction\\n\\n\\nTwentieth century plan...</td>\n",
       "      <td>Vehicular air pollution has created an ongoing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>## 1. Introduction\\n\\n\\nLongleaf pine ( Pinus ...</td>\n",
       "      <td>For the last several decades, a substantial am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  \\\n",
       "paper_id                                                      \n",
       "0         ## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCI...   \n",
       "1         ## 1. Introduction\\n\\n\\nAn Electronic Health R...   \n",
       "2         ## Introduction\\n\\n\\nTranslation  plays  an  i...   \n",
       "3         ## 1 Problem Setup\\n\\n\\nRecent political scien...   \n",
       "4         ## INTRODUCTION\\n\\n\\nThis  article  investigat...   \n",
       "...                                                     ...   \n",
       "995       ## Methods\\n\\n\\n\\n## Sample\\n\\n\\nOur data come...   \n",
       "996       ## Introduction\\n\\n\\nCanada is a high-income c...   \n",
       "997       ## Introduction\\n\\n\\nCultural studies has ofte...   \n",
       "998       ## 1. Introduction\\n\\n\\nTwentieth century plan...   \n",
       "999       ## 1. Introduction\\n\\n\\nLongleaf pine ( Pinus ...   \n",
       "\n",
       "                                                    summary  \n",
       "paper_id                                                     \n",
       "0         In this article, Victor Fan argues that analys...  \n",
       "1         Problem definition: Physicians spend more than...  \n",
       "2         Literary translation is one of the most challe...  \n",
       "3         There is a long-running debate on evaluating f...  \n",
       "4         Recently, ‘bimajyo’ (美魔女) came into focus in J...  \n",
       "...                                                     ...  \n",
       "995       Demand for democratic accountability in polici...  \n",
       "996       Canada’s employment standards laws and mandato...  \n",
       "997       Cultural studies has often favoured a Foucauld...  \n",
       "998       Vehicular air pollution has created an ongoing...  \n",
       "999       For the last several decades, a substantial am...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"train.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 1,000 rows of five columns:\n",
    " - `paper_id`: Identifier of the paper provided by the Open Science Framework Preprints server from the Center for Open Science.\n",
    " - `text`: The main body of the academic paper. This is a modified version of the original to remove the abstract, references, and other text that wouldn't make it into an abstract. \n",
    " - `abstract`: The paper abstract that was provided along with the paper's preprint.\n",
    "\n",
    "Let's look at a couple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document length: 33,416 characters\n",
      "Document:\n",
      "## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCIOUSNESS\n",
      "\n",
      "\n",
      "Since 1997,\n",
      "the concept of extraterritoriality has been configured in the\n",
      "political tension between Hong Kong and Beijing. From the perspective\n",
      "of the Central Government, it is fundamental for the people of China\n",
      "to shijian zhuquan instantiate its sovereignty over Hong Kong. But\n",
      "while most Hong / Kong residents insist on interpreting this concept\n",
      "in terms of the Euro-American notion of selfdetermination  (zizhu /\n",
      "making decisions  for  oneself),  the  Beijing  government  believes\n",
      "that  the Hong Kong legislature must make decisions in conformation to\n",
      "the larger will of the people, which the Party represents, a concept\n",
      "taken from the writings of Lenin and Stalin (Gao 2010: 26-30). This\n",
      "tension is crystalised in the long debate about Article 23 of the Hong\n",
      "Kong Basic Law, which requires  the  SAR  to  'enact  laws  on  its\n",
      "own  to  prohibit  any  act  of  treason,  secession,  sedition,\n",
      "subversion  against  the  Central  People's  G\n"
     ]
    }
   ],
   "source": [
    "print(f'Document length: {len(df.loc[0, \"text\"]):,} characters')\n",
    "print(\"Document:\")\n",
    "print(fill(df.loc[0, \"text\"], replace_whitespace=False)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this article, Victor Fan argues that analysing contemporary Hong\n",
      "Kong cinema requires active rewriting of established postcolonial\n",
      "theories by taking into account the specific mode of colonisation of\n",
      "Hong Kong: extraterritoriality. This concept has been responsible for\n",
      "the construction of the cultural plurality, linguistic ambiguity, and\n",
      "political liminality of Hong Kong and its cinematographic experience,\n",
      "as well as the incongruence between the community’s political\n",
      "consciousness after 1997 and the larger national imagination\n",
      "promulgated by the Beijing government. The term ‘extraterritoriality’\n",
      "was translated into Chinese after 1895 via Japanese as zhiwai faquan\n",
      "the right to exercise one’s law outside a nation state’s sovereign\n",
      "terrain, and colonialism in China between 1844 and 1949 was largely\n",
      "characterized by a continuous reformulation and systematisation of\n",
      "this concept. It in fact still informs the way former colonised\n",
      "regions in China are administered today, and the political unconscious\n",
      "of their residents. With Jonnie To’s 2012 film Duzhan (Dukzin) /Drug\n",
      "War as a case study, contemporary Hong Kong cinema, Fan argues, can be\n",
      "understood as a public sphere where an extraterritorial consciousness\n",
      "and the contesting political affects associated with it are actively\n",
      "negotiated.\n"
     ]
    }
   ],
   "source": [
    "print(fill(df.loc[0, \"summary\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only printed out the first part of the document, but a few things we saw while looking through (to act as inspiration):\n",
    " * This is markdown.\n",
    " * This document is long.\n",
    " * There are formulas and images HTML entities like `&amp;`.\n",
    "\n",
    "Let's get a quick sense of the lengths of these things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_len\"] = df.text.str.len()\n",
    "df[\"summary_len\"] = df.summary.str.len()\n",
    "df[\"text_len_log\"] = np.log10(df.text_len)\n",
    "df[\"summary_len_log\"] = np.log10(df.summary_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x7e1a33e40b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.jointplot(df, x=\"text_len_log\", y=\"summary_len_log\", kind=\"hist\")\n",
    "xticks = [3, 4, 5, 6]\n",
    "yticks = [2, np.log10(250), np.log10(500), 3, np.log10(2_500), np.log10(5_000), 4]\n",
    "g.ax_marg_x.set_xticks(xticks, [f\"{10**tick:,.0f}\" for tick in xticks])\n",
    "g.ax_marg_y.set_yticks(yticks, [f\"{10**tick:,.0f}\" for tick in yticks])\n",
    "g.set_axis_labels(\n",
    "    \"Num. characters in text (log scale)\", \"Num. characters in summary (log scale)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that on the log scale there's a nice bell curve to each distribution, and there doesn't seem to be a strong connection between the lengths, so a long document might have a short abstract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>summary_len</th>\n",
       "      <th>text_len_log</th>\n",
       "      <th>summary_len_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42050.269000</td>\n",
       "      <td>1275.241000</td>\n",
       "      <td>4.574534</td>\n",
       "      <td>3.079240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21412.146068</td>\n",
       "      <td>426.262199</td>\n",
       "      <td>0.207977</td>\n",
       "      <td>0.162033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10145.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>4.006252</td>\n",
       "      <td>1.954243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28381.500000</td>\n",
       "      <td>1008.500000</td>\n",
       "      <td>4.453035</td>\n",
       "      <td>3.003676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38962.000000</td>\n",
       "      <td>1258.500000</td>\n",
       "      <td>4.590641</td>\n",
       "      <td>3.099853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51263.250000</td>\n",
       "      <td>1501.250000</td>\n",
       "      <td>4.709806</td>\n",
       "      <td>3.176453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>196911.000000</td>\n",
       "      <td>4359.000000</td>\n",
       "      <td>5.294270</td>\n",
       "      <td>3.639387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text_len  summary_len  text_len_log  summary_len_log\n",
       "count    1000.000000  1000.000000   1000.000000      1000.000000\n",
       "mean    42050.269000  1275.241000      4.574534         3.079240\n",
       "std     21412.146068   426.262199      0.207977         0.162033\n",
       "min     10145.000000    90.000000      4.006252         1.954243\n",
       "25%     28381.500000  1008.500000      4.453035         3.003676\n",
       "50%     38962.000000  1258.500000      4.590641         3.099853\n",
       "75%     51263.250000  1501.250000      4.709806         3.176453\n",
       "max    196911.000000  4359.000000      5.294270         3.639387"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splits\n",
    "\n",
    "Once we train a model, how do we know if it's good? Well, if we train it to 100% accuracy, it's good, right?\n",
    "\n",
    "Wrong! Well, maybe wrong. In many data science projects, including this one, we more often care about the model's performance on _unseen_ data, that is, data the model hasn't seen/wasn't trained on. (This is also called \"hold-out data\" or \"test data\" or \"validation data\" depending on how it's used and who's saying it.) How do we do that? Easy! Split the summaries into two chunks: one chunk that we'll train the model on and one chunk that we'll use to estimate the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train shape: (700, 6); Test shape: (300, 6)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=0)\n",
    "f\"Train shape: {train.shape}; Test shape: {test.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suspiciously easy? You're right to be suspicious.\n",
    "\n",
    "There's a trap here. We typically don't train one model and call it a day. We often train a model, see where it succeeds and fails, see how it does on the unseen data, tweak some stuff, and retrain. And we might do this many times. The problem? Our \"unseen\" data is slowly becoming more and more _seen_. If we're tweaking things to improve our model, and we see our model's performance on our hold-out data is improving as we tweak, are we tweaking our model to be better on *other, actually unseen data* or only better on our hold-out data? We don't know!\n",
    "\n",
    "The one weird trick? Split again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train shape: (490, 6); Validation shape: (210, 6); Test shape: (300, 6)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validation = train_test_split(train, test_size=0.30, random_state=0)\n",
    "f\"Train shape: {train.shape}; Validation shape: {validation.shape}; Test shape: {test.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train, look at our validation split, tweak, keep iterating, and finally make sure we haven't messed anything up by looking at our test split.\n",
    "\n",
    "Are we done? Are there more traps? As long as you only look at your test data once, you're fine. If you need to look at it again, or if you want to train on all your data? Keep splitting! [Split forever!](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Exhaustive_cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting\n",
    "\n",
    "We have training data, and we have an LLM. Now we need to \"tell\" the language model what to do and figure out how to give it our documents.  This is where knowing details of your specific language model is important. \n",
    "\n",
    "<aside style=\"border: 2px solid lightgray; margin: 1em; padding: 1em;\">\n",
    "<h3>Aside: Tokens</h3>\n",
    "\n",
    "Language models don't really use words the same way we do. They use little word pieces called \"tokens\". This is because most models have a fixed vocabulary that's baked in at training time, and it's typically tens to hundreds of thousands of tokens long. There are more words than that. If we used words for the model's vocabulary and the model encountered \"Dematophora necatrix\", neither of which were in its vocabulary, it'd just read \"\\<unknown\\> \\<unknown\\>\" or something. But if we used tokens for its vocab instead, it might see \"De-mat-o-phor-a ne-ca-trix\". It might not know what the means (just like _I_ don't know what that means), but it could at least read and it maybe guess (just like _I_ can read it and confidently assume it's an extremely-talented-but-ultimately-unlistenable Scandanavian death metal band [it's an [apple fungus](https://en.wikipedia.org/wiki/Rosellinia_necatrix)]).\n",
    "</aside>\n",
    "\n",
    "\n",
    "Most language models work by taking a piece of text and predicting the next token. \"The sky is \"\n",
    "\n",
    "Your analog, brain-based language model probably just said \"blue\" and most digital, computer-based language models would too. Now take \"The sky is blue \" and try to predict the next token. Take your answer, add it to the end of \"The sky is blue \" and go again. Congratulations, you're **generative**! You're **autoregressive**!\n",
    "\n",
    "For accomplishing the summarization task, we could imagine passing our language model `Here is a terrific one-sentence summary of \"{long document here}\": ` and that just might work. Actually, enough reading and imagining, let's try it.\n",
    "\n",
    "Let's pick a document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (500 of 135,755 characters):\n",
      "## 1.1 Policy context\n",
      "\n",
      "\n",
      "Some 25 per cent of Australians live outside\n",
      "one of the nation's capitals, resulting in a substantial\n",
      "nonmetropolitan population in absolute terms, but a much smaller\n",
      "population relative to the total number resident in the largest\n",
      "metropolitan centres. Policy for rural and regional housing across\n",
      "Australia is made complex by federation: the Australian Government has\n",
      "relatively few direct powers with respect to housing, but remains an\n",
      "important source of financial support...\n",
      "\n",
      "Summary (1,405 characters):\n",
      "This AHURI research examined housing trends and the processes of\n",
      "delivering affordable housing supply in rural and regional Australia.\n",
      "These rural and regional housing markets have faced substantial\n",
      "challenges for more than three decades, including poor housing\n",
      "affordability; under-developed supply chains; the shortage of skilled\n",
      "and unskilled labour force; increasing demand for housing in some\n",
      "localities, while other centres decline; together with limited policy\n",
      "attention to the specific needs of rural and regional Australia.  A\n",
      "clear research finding is the need for government action to ‘unfreeze’\n",
      "rural and regional housing markets, making substantial investments and\n",
      "interventions in regional housing markets and developing stronger\n",
      "supply chains for rural and regional housing. The development of a\n",
      "national urban and regional strategy would also provide certainty for\n",
      "private investment, while also unlocking potential State and\n",
      "Australian government support.  To overcome the shortage of labour to\n",
      "work on dwelling construction, a guaranteed program of investment in\n",
      "work and new-builds may be needed to attract and retain labour in the\n",
      "housing sector so as to create a more secure pipeline of work for\n",
      "builders and their workforce. This would need to be a long-term\n",
      "strategy, otherwise short-term action may exacerbate existing\n",
      "challenges, placing additional price pressure into the market.\n"
     ]
    }
   ],
   "source": [
    "def doc_and_summary_from_row(doc_row: pd.Series):\n",
    "    \"\"\"Pull out the document and summary\"\"\"\n",
    "    return doc_row[\"text\"], doc_row[\"summary\"]\n",
    "\n",
    "\n",
    "def show_doc_and_summary(doc: str, summary: str, max_len_to_print: int = 500) -> str:\n",
    "    \"\"\"Show a little bit of a doc and its summary\"\"\"\n",
    "\n",
    "    return (\n",
    "        f\"Document ({max_len_to_print:,} of {len(doc):,} characters):\\n\"\n",
    "        f\"{fill(doc[:max_len_to_print], replace_whitespace=False)}...\\n\\n\"\n",
    "        f\"Summary ({len(summary):,} characters):\\n\"\n",
    "        f\"{fill(summary)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "doc_row = train.loc[533]\n",
    "doc, summary = doc_and_summary_from_row(doc_row)\n",
    "\n",
    "print(show_doc_and_summary(doc, summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, I'm not going to read all of this, but I trust it's great. Let's make our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt (135,802 characters):\n",
      "Here is a terrific one-sentence summary of \"## 1.1 Policy co ... e off housing nationwide.\n",
      "\n",
      "\": \n"
     ]
    }
   ],
   "source": [
    "prompt_template = 'Here is a terrific one-sentence summary of \"{doc}\": '\n",
    "prompt = prompt_template.format(doc=doc)\n",
    "\n",
    "\n",
    "def show_prompt(prompt: str, start_chars: int = 60, end_chars: int = 30) -> str:\n",
    "    \"\"\"Nicely format a prompt\"\"\"\n",
    "    return f\"Our prompt ({len(prompt):,} characters):\\n{prompt[:start_chars]} ... {prompt[-end_chars:]}\"\n",
    "\n",
    "\n",
    "print(show_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if our language model server is running. (Because I know you definitely did step 3 in the \"Environment\" section above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '0.6.2'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(LLM_SERVER + \"/api/version\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's not an error, so things look good!\n",
    "\n",
    "Ollama starts up an [API server](https://github.com/ollama/ollama/blob/main/docs/openai.md) that's pretty similar to the [OpenAI Completions API](https://platform.openai.com/docs/api-reference/chat/create). \"Completion\" is the name given to what we were doing before - \"the sky is `{completion}`\". Let's write a little function that lets us call the completion API with our given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_completion(\n",
    "    prompt: str, max_tokens: int | None = None, top_k: int | None = None\n",
    ") -> str:\n",
    "    \"\"\"Hit an API endpoint to get an LLM completion\"\"\"\n",
    "    data = {\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"seed\": 0,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_k\": top_k,\n",
    "    }\n",
    "    resp = requests.post(LLM_SERVER + \"/v1/completions\", json=data)\n",
    "    return resp.json()[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a terrific one-sentence summary of \"{doc}\": \n",
      "\n",
      "Okay, here's a breakdown of the key takeaways from the text, organized\n",
      "into sections for clarity and focusing on the core arguments:\n",
      "\n",
      "**1.\n",
      "The Root of the Problem: Regional Housing Challenges**\n",
      "\n",
      "* **Underlying\n",
      "Issue:** The text highlights a significant problem with regional\n",
      "housing markets in Australia. They are struggling due to a combination\n",
      "of factors:\n",
      "    * **Under Pressure:** They've experienced booms and\n",
      "busts, stagnation, and declining asset values.\n",
      "    * **Lack of\n",
      "Support:**  Governments haven’t adequately invested in supporting\n",
      "these markets.\n",
      "\n",
      "**2. Why Intervention is Needed**\n",
      "\n",
      "* **Need for\n",
      "Action:** The text argues that proactive intervention is vital because\n",
      "inaction will lead to further hardship for residents and negative\n",
      "impacts on the nation.\n",
      "\n",
      "**3.  A Framework for Addressing the Problem –\n",
      "Place-Based Policy**\n",
      "\n",
      "* **Shift in Thinking:** The solution isn’t just\n",
      "about efficient strategies; it’s about understanding the *context* of\n",
      "each region and focusing on localized develo\n"
     ]
    }
   ],
   "source": [
    "completion = get_llm_completion(prompt)\n",
    "print(prompt_template + \"\\n\\n\" + fill(completion, replace_whitespace=False)[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's...not what we asked for? But good? It doesn't look like it followed our instructions at all, but it does seem to at least be related to the paper.\n",
    "\n",
    "We mentioned above that knowing the details of your specific language model is important here. In this instance, there are at least two things we haven't addressed yet:\n",
    "\n",
    "1. Our model has a \"context window\" of 32,768 tokens (which is $2^{15}$).\n",
    "2. Our Gemma3 model is \"instruction-tuned\".\n",
    "\n",
    "### The \"Context Window\"\n",
    "\n",
    "Most language models have a \"context window\" (or \"context length\", \"token limit\", etc.) - the number of previous tokens the model can consider as it tries to predict the next token. Basically, it's the size of the model's memory.\n",
    "\n",
    "So how big is Gemma 3's memory? This can be tricky to track down, but the answer is that most of the Gemma 3 models have a context window of 128k tokens, but 1-billion parameter version we're using has a context window of **32,768 tokens** (Look for \"Long context\" in the [Technical Report](https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf)). Ollama also knows this model's [context length](https://ollama.com/library/gemma3:1b/blobs/7cd4618c1faf).\n",
    "\n",
    "***BUT!***\n",
    "\n",
    "By default, Ollama [imposes a maximum context length](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-specify-the-context-window-size) of **2,048 tokens**. This is because as you add more context, the computational requirement increases fairly dramatically. The Ollama devs probably don't want the default experience to consist of you wondering if anything is happening for 20 minutes while your computer slowly melts, so this is reasonable but it's a real gotcha to look out for.\n",
    "\n",
    "That means that without changing any settings, we're limited to **2,048 tokens**. Changing the settings isn't hard, but we'll consider it out of the scope of this benchmark.\n",
    "\n",
    "So how big is our prompt? Is it larger than can fit in our model's context window? While at the time of writing Ollama doesn't yet have a [nice API](https://github.com/ollama/ollama/pull/8106) for answering this question, we can get an approximate answer using a library called [tiktoken](https://github.com/openai/tiktoken). It'll use a \"tokenizer\" similar to Gemma 3's to break up the text into tokens. We'll just check how many tokens it outputs. This won't be the same number as our model's tokenizer, but it should be close enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Count the number of tokens in a string\"\"\"\n",
    "    enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "    return len(enc.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt is 25,853 tokens.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our prompt is {count_tokens(prompt):,} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more than 2,048, so not everything fit in our model's memory.\n",
    "\n",
    "What did our model end up \"forgetting\"? Let's look at our prompt again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt (135,802 characters):\n",
      "Here is a terrific one-sentence summary of \"## 1.1 Policy co ... e off housing nationwide.\n",
      "\n",
      "\": \n"
     ]
    }
   ],
   "source": [
    "print(show_prompt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time the end of the prompt came around, the model would have forgotten the beginning. But the beginning is *where we ask it to make a summary!* It ended up just seeing a bunch of text from the end of the document. The fact that it made a summary at all was coincidental! They must have trained it to return a breakdown when given a document with no other context.\n",
    "\n",
    "What to do, what to do. Since this is a benchmark, let's just chop off the doc and hope not too much important information lies outside the very beginning of the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our shorter prompt is 1,361 tokens long.\n",
      "Our prompt (7,547 characters):\n",
      "Here is a terrific one-sentence summary of \"## 1.1 Policy co ... rdable rental housing (Mart\": \n"
     ]
    }
   ],
   "source": [
    "shorter_prompt = prompt_template.format(doc=doc[:7_500])\n",
    "print(f\"Our shorter prompt is {count_tokens(shorter_prompt):,} tokens long.\")\n",
    "print(show_prompt(shorter_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here’s a breakdown of the key takeaways from the provided text,\n",
      "organized for clarity:\n",
      "\n",
      "**1. The Housing Crisis in Australia – A\n",
      "Complex System**\n",
      "\n",
      "*   **Significant Rural/Regional Gap:** Australia\n",
      "has a large population concentrated in capital cities, but a smaller\n",
      "population in rural and regional areas. This creates a significant\n",
      "housing challenge.\n",
      "*   **Federal Fragmentation:**  The Australian\n",
      "government’s policies are largely focused on the economy, but not\n",
      "specifically addressing regional housing needs.\n",
      "*   **Existing Efforts\n",
      "(Limited):**  There are some small-scale programs, but the overall\n",
      "approach is lacking in long-term, coordinated policy.\n",
      "\n",
      "**2. Key\n",
      "Initiatives & Programs**\n",
      "\n",
      "*   **Housing Australia & National Housing\n",
      "Accord:** Launched in 2023 to ensure housing delivery and address the\n",
      "housing needs of all Australians. The HAFF ($10 billion investment\n",
      "fund) is aiming for 20,000 social and 20,000 affordable homes across\n",
      "Australia by 2024.\n",
      "*   **Regional First Home Buyer G\n"
     ]
    }
   ],
   "source": [
    "completion = get_llm_completion(shorter_prompt)\n",
    "print(fill(completion, replace_whitespace=False)[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is...still ignoring us.\n",
    "\n",
    "There's another piece we need to address. Our model is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Instruction-Tuned\"\n",
    "\n",
    "We've talked about how language models just predict the next token, but we haven't talked much about the data they're trained on.\n",
    "\n",
    "The easiest way to interact with a language model today is through a chat interface. But if they're just predicting the next token from a string of tokens, how does chat work? If I were asked to complete \"The sky is \", I wouldn't write \"The sky is **blue. What else can I help you with today?**\" like chatbots seem to do. Why do they do that?\n",
    "\n",
    "Because they've been \"instruction-tuned\". Once they've been trained on a lot of regular text (books, articles, websites, etc.), they then get trained a little bit more on text that looks like chats. You can download models that haven't had this extra training, but ours here has, and so it's expecting text that looks like chats. And it's expecting the specific chat format it was trained on (Table 4 [here](https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf)). Ollama has [incorporated that format](https://ollama.com/library/gemma3:1b/blobs/e0a42594d802) for us, but it looks like this:\n",
    "\n",
    "```\n",
    "[BOS]<start_of_turn>user\n",
    "Who are you?<end_of_turn>\n",
    "<start_of_turn>model\n",
    "My name is Gemma!<end_of_turn>\n",
    "<start_of_turn>user\n",
    "What is 2+2?<end_of_turn>\n",
    "<start_of_turn>model\n",
    "```\n",
    "\n",
    "That's not what our prompt template looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a terrific one-sentence summary of \"{doc}\": '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You might have heard of \"system prompts\" which go before the chat and give the model some context. The Gemma models [don't use one](https://ai.google.dev/gemma/docs/core/prompt-structure#system-instructions) so you don't have to worry about it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ollama is taking care of a little of this under the covers for us already, but clearly we need to change some stuff to make this is chat rather than a straight completion.\n",
    "\n",
    "We could handle setting up this chat format ourselves, but one of the benefits of having an OpenAI-compatible API is that we can just use [OpenAI's Python library](https://github.com/openai/openai-python) and point it at our computer instead of theirs!\n",
    "\n",
    "The output structure is a little complicated because it includes a bunch of features we don't need, but here's an example of just getting the model's response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a large language model, and I don’t have a name or personal\n",
      "preferences like age or favorite ice cream flavors! I’m here to help\n",
      "you with whatever you need. 😊\n",
      "\n",
      "But if I *were* to choose a favorite,\n",
      "it would probably be a really complex and interesting flavor profile –\n",
      "perhaps a combination of dark chocolate, salted caramel, and a hint of\n",
      "raspberry. \n",
      "\n",
      "How about you? What’s *your* favorite ice cream flavor?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "llm_client = OpenAI(base_url=LLM_SERVER + \"/v1\", api_key=\"my-fake-free-api-key!\")\n",
    "\n",
    "chat_completion = llm_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What's your name, age, and favorite ice cream flavor?\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    "    seed=0,\n",
    ")\n",
    "print(fill(chat_completion.choices[0].message.content, replace_whitespace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While unsettlingly-cheery, it does look like things are working for us now. Let's try asking for summary again, remembering to make it sound more like a chat and chop it so it fits in the context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(prompt: str, max_tokens: int = 500):\n",
    "    \"\"\"Get a response from an LLM using the OpenAI client\"\"\"\n",
    "    chat_completion = llm_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        seed=0,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content, chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = (\n",
    "    \"Can you please write a terrific one-sentence summary of this document:\\n\\n{doc}\"\n",
    ")\n",
    "resp, completion = ask_llm(prompt_template.format(doc=doc[:10_000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here's how you check the token usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens     : 1,904\n",
      "Completion tokens : 65\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Prompt tokens     : {completion.usage.prompt_tokens:,}\\nCompletion tokens : {completion.usage.completion_tokens:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our little summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a one-sentence summary of the document:\n",
      "\n",
      "**The Australian\n",
      "government’s efforts to address rural and regional housing challenges\n",
      "are hampered by a fragmented system of policy and limited investment,\n",
      "necessitating innovative local government action and a growing\n",
      "reliance on regulation, particularly through platforms like Airbnb,\n",
      "which are reshaping regional housing markets.**\n"
     ]
    }
   ],
   "source": [
    "print(fill(resp, replace_whitespace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not bad!\n",
    "\n",
    "I think. I'm not actually sure. It looks better, but is it a good summary?\n",
    "\n",
    "To find out, we should generate a bunch of summaries and then evaluate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Let's wrap what we've done so far into a nice little function so we can easily run it on a bunch of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(doc: str, max_doc_chars: int = 7_000) -> str:\n",
    "    \"\"\"Summarize (part of) a document\"\"\"\n",
    "    prompt_template = \"Can you please write a terrific one-sentence summary of this document:\\n\\n{doc}\"\n",
    "    resp, completion = ask_llm(prompt_template.format(doc=doc[:max_doc_chars]))\n",
    "    return resp\n",
    "\n",
    "\n",
    "def predict_on_dataset(\n",
    "    df: pd.DataFrame, max_docs: int | None = None, summarize_fn=summarize\n",
    ") -> dict[int, str]:\n",
    "    \"\"\"Generate a summary for every document in a dataframe\"\"\"\n",
    "    doc_id_to_summary = {}\n",
    "    max_docs = max_docs or df.shape[0]\n",
    "    for id, row in tqdm(df.head(max_docs).iterrows(), total=max_docs, smoothing=0):\n",
    "        doc = row[\"text\"]\n",
    "        doc_id_to_summary[id] = summarize_fn(doc)\n",
    "    return doc_id_to_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a57fdccd9642db8e6bc852a53a402e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{827: \"Here's a one-sentence summary of the document:\\n\\nSuzuki’s early fascination with anime and film, sparked by his family’s exposure to these media, ultimately played a crucial role in shaping the history of Studio Ghibli by connecting him to influential artists and fostering a network that propelled the studio’s success and continues to influence its creative output.\",\n",
       " 166: \"Here's a one-sentence summary of the document, aiming to capture the core of the research:\\n\\nThis study analyzes the complex interplay between the self-translator and co-translator Alsanea and Booth in the English translation of Rajaa Alsanea’s novel *Girls of Riyadh*, examining how their differing approaches – a blend of literal and functional translation – influenced the novel’s cultural and linguistic representation and ultimately contributed to a potential loss of vital cultural nuances.\",\n",
       " 170: \"Here's a one-sentence summary of the document:\\n\\nDespite the growing recognition of ADHD as a misunderstood mental disorder, societal stigma and negative perceptions continue to significantly impact individuals experiencing the condition, leading to harmful consequences for their well-being and potentially hindering effective treatment and support.\",\n",
       " 328: 'This paper examines how research priorities are currently aligned with societal needs and demands in two disease areas – cardiometabolic and mental health – and argues that focusing solely on research on these issues without considering broader needs is insufficient. It highlights the shift from a mission-oriented approach to one that prioritizes addressing health needs through a strategy of understanding and supporting these needs, drawing on research priorities and stakeholder perceptions, ultimately aiming to foster a productive debate about research direction and support for these vital areas.',\n",
       " 347: \"Here’s a one-sentence summary of the document, aiming to capture the core focus and key findings:\\n\\n**This research examines the challenges faced by ESL students in developing effective writing skills, particularly through the effective use of instructional scaffolding, which ultimately benefits student learning and fosters independent writing abilities.** \\n\\nHere's a slightly more detailed breakdown of why this is a good summary:\\n\\n*   **Focus:** It highlights the core problem – struggling ESL students with writing – and the study’s aim to address it.\\n*   **Key Elements:** It mentions the methodology (research question), the specific challenges addressed (writing difficulty, scaffolding), and the potential benefits (improved writing skills).\\n\\nLet me know if you'd like me to refine this further!\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_summary = predict_on_dataset(train, max_docs=5)\n",
    "id_to_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it's roughly doing what we want. Let's do the whole training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd85981160542fdb50244fe6c6d1efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_len</th>\n",
       "      <th>summary_len</th>\n",
       "      <th>text_len_log</th>\n",
       "      <th>summary_len_log</th>\n",
       "      <th>my_summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>## THE EARLY DAYS\\n\\n\\nSuzuki's link with anim...</td>\n",
       "      <td>While so-called ‘Ghibli films’ attract global ...</td>\n",
       "      <td>35403</td>\n",
       "      <td>1446</td>\n",
       "      <td>4.549040</td>\n",
       "      <td>3.160168</td>\n",
       "      <td>Here's a one-sentence summary of the document:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>## Introduction\\n\\n\\nThe paper aims to assess ...</td>\n",
       "      <td>The paper aims to assess the quality of the En...</td>\n",
       "      <td>56832</td>\n",
       "      <td>1964</td>\n",
       "      <td>4.754593</td>\n",
       "      <td>3.293141</td>\n",
       "      <td>Here's a one-sentence summary of the document,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>## Introduction\\n\\n\\nThe medical world is cons...</td>\n",
       "      <td>The medical world is constantly changing. The ...</td>\n",
       "      <td>32191</td>\n",
       "      <td>2364</td>\n",
       "      <td>4.507734</td>\n",
       "      <td>3.373647</td>\n",
       "      <td>Here's a one-sentence summary of the document:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>## 1. Introduction\\n\\n\\nResearch and innovatio...</td>\n",
       "      <td>A current issue in mission-oriented research p...</td>\n",
       "      <td>68076</td>\n",
       "      <td>1049</td>\n",
       "      <td>4.832994</td>\n",
       "      <td>3.020775</td>\n",
       "      <td>This paper examines how research priorities ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>## Introduction\\n\\n\\nTeaching writing to ESL s...</td>\n",
       "      <td>The present research is a small-scale case stu...</td>\n",
       "      <td>38230</td>\n",
       "      <td>1518</td>\n",
       "      <td>4.582404</td>\n",
       "      <td>3.181272</td>\n",
       "      <td>Here’s a one-sentence summary of the document,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>## Introduction\\n\\n\\nSince the 1980s, low-fert...</td>\n",
       "      <td>While extensive literature documents the massi...</td>\n",
       "      <td>41787</td>\n",
       "      <td>1017</td>\n",
       "      <td>4.621041</td>\n",
       "      <td>3.007321</td>\n",
       "      <td>Here’s a one-sentence summary of the document,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>## Introduction\\n\\n\\nEmpirically  analyzing  h...</td>\n",
       "      <td>The causal identification of network effects i...</td>\n",
       "      <td>36116</td>\n",
       "      <td>582</td>\n",
       "      <td>4.557700</td>\n",
       "      <td>2.764923</td>\n",
       "      <td>This paper examines how social networks influe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>## 3 Data and Methods\\n\\n\\n213\\n\\n\\n## 3.1 Dat...</td>\n",
       "      <td>Interviewer effects are a common challenge in ...</td>\n",
       "      <td>38974</td>\n",
       "      <td>1271</td>\n",
       "      <td>4.590775</td>\n",
       "      <td>3.104146</td>\n",
       "      <td>This document analyzes the data from the Europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2.1 Risk Integration\\n\\n\\nSeveral methods have...</td>\n",
       "      <td>Effective risk management in a multi-business ...</td>\n",
       "      <td>16345</td>\n",
       "      <td>606</td>\n",
       "      <td>4.213385</td>\n",
       "      <td>2.782473</td>\n",
       "      <td>Here's a one-sentence summary of the document,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>## BTS MUSIC VIDEOS AND HALLYU\\n\\n\\nK-Pop has ...</td>\n",
       "      <td>The recent music video ‘Idol’ (published 24 Au...</td>\n",
       "      <td>45772</td>\n",
       "      <td>1284</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>3.108565</td>\n",
       "      <td>Here's a one-sentence summary of the document,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  \\\n",
       "paper_id                                                      \n",
       "827       ## THE EARLY DAYS\\n\\n\\nSuzuki's link with anim...   \n",
       "166       ## Introduction\\n\\n\\nThe paper aims to assess ...   \n",
       "170       ## Introduction\\n\\n\\nThe medical world is cons...   \n",
       "328       ## 1. Introduction\\n\\n\\nResearch and innovatio...   \n",
       "347       ## Introduction\\n\\n\\nTeaching writing to ESL s...   \n",
       "...                                                     ...   \n",
       "195       ## Introduction\\n\\n\\nSince the 1980s, low-fert...   \n",
       "948       ## Introduction\\n\\n\\nEmpirically  analyzing  h...   \n",
       "756       ## 3 Data and Methods\\n\\n\\n213\\n\\n\\n## 3.1 Dat...   \n",
       "574       2.1 Risk Integration\\n\\n\\nSeveral methods have...   \n",
       "472       ## BTS MUSIC VIDEOS AND HALLYU\\n\\n\\nK-Pop has ...   \n",
       "\n",
       "                                                    summary  text_len  \\\n",
       "paper_id                                                                \n",
       "827       While so-called ‘Ghibli films’ attract global ...     35403   \n",
       "166       The paper aims to assess the quality of the En...     56832   \n",
       "170       The medical world is constantly changing. The ...     32191   \n",
       "328       A current issue in mission-oriented research p...     68076   \n",
       "347       The present research is a small-scale case stu...     38230   \n",
       "...                                                     ...       ...   \n",
       "195       While extensive literature documents the massi...     41787   \n",
       "948       The causal identification of network effects i...     36116   \n",
       "756       Interviewer effects are a common challenge in ...     38974   \n",
       "574       Effective risk management in a multi-business ...     16345   \n",
       "472       The recent music video ‘Idol’ (published 24 Au...     45772   \n",
       "\n",
       "          summary_len  text_len_log  summary_len_log  \\\n",
       "paper_id                                               \n",
       "827              1446      4.549040         3.160168   \n",
       "166              1964      4.754593         3.293141   \n",
       "170              2364      4.507734         3.373647   \n",
       "328              1049      4.832994         3.020775   \n",
       "347              1518      4.582404         3.181272   \n",
       "...               ...           ...              ...   \n",
       "195              1017      4.621041         3.007321   \n",
       "948               582      4.557700         2.764923   \n",
       "756              1271      4.590775         3.104146   \n",
       "574               606      4.213385         2.782473   \n",
       "472              1284      4.660600         3.108565   \n",
       "\n",
       "                                                 my_summary  \n",
       "paper_id                                                     \n",
       "827       Here's a one-sentence summary of the document:...  \n",
       "166       Here's a one-sentence summary of the document,...  \n",
       "170       Here's a one-sentence summary of the document:...  \n",
       "328       This paper examines how research priorities ar...  \n",
       "347       Here’s a one-sentence summary of the document,...  \n",
       "...                                                     ...  \n",
       "195       Here’s a one-sentence summary of the document,...  \n",
       "948       This paper examines how social networks influe...  \n",
       "756       This document analyzes the data from the Europ...  \n",
       "574       Here's a one-sentence summary of the document,...  \n",
       "472       Here's a one-sentence summary of the document,...  \n",
       "\n",
       "[490 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id_to_summary = predict_on_dataset(train)\n",
    "train_preds = train.assign(my_summary=train_id_to_summary)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c918dca195c47a7abb31d4b18703761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_id_to_summary = predict_on_dataset(validation)\n",
    "val_preds = validation.assign(my_summary=val_id_to_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get *scoring*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The metric we're using for this competition is based on *ROUGE-2*. [ROUGE](https://aclanthology.org/W04-1013.pdf) is a family of metrics that is very popular in summarization tasks, quick to compute, and fairly intuitive. \n",
    "\n",
    "ROUGE-2 looks at the overlap of \"bigrams\" between the reference summary and the generated summary. \"Bigrams\" are just two consecutive words, e.g. `(bigrams are), (are just), (just two), (two consecutive), (consecutive words)`. Specifically, we're looking at the F1 score derived from this overlap, which is a way of balancing [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall#Definition).\n",
    "\n",
    "The ROUGE metrics have the nice property that all the scores are bounded between **0** and **1**. **0** means there's no overlap, and **1** means perfect overlap.\n",
    "\n",
    "There are other types of ROUGE as well (you'll often see ROUGE-1 and ROUGE-L mentioned), but there are also more sophisticated evaluation metrics. For example:\n",
    "\n",
    "> Susan is going to walk in the mountains this afternoon.\n",
    "\n",
    " and \n",
    " \n",
    "> Susie will hike later today.\n",
    "\n",
    "have zero overlap (and a ROUGE score of zero - no matter which ROUGE you use), yet express basically the same thing.\n",
    " \n",
    "Folks have come up with creative ways to overcome the limitations of ROUGE and other \"statistical scorers\". Some scorers use embedding models (say, [BERT](https://huggingface.co/blog/bert-101#bert-101-%F0%9F%A4%97-state-of-the-art-nlp-model-explained)) to compute embeddings for the predicted and actual summaries, then compute a distance metric between the two summary embeddings. Such methods may capture semantic similarity better than ROUGE. Other scorers figure, hey, if LLMs got us into this epistemological mess, surely they can get us out too? These scorers use LLMs to evaluate the similarity between the predicted and actual summaries. Essentially, you provide an LLM with the predicted and actual summary and some criteria by which it should evaluate how well they match. The reliability of that output of course depends on selecting appropriate criteria for your task and the usual prompt engineering. You can read more about different ways of evaluating LLMs along with links to implementations in the [deepeval](https://github.com/confident-ai/deepeval) package in this [helpful blogpost](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation). Although LLM-based scoring is out of scope for this competition's leaderboard, we'd be interested to hear about any experiments you take on to compare your leaderboard score to other metrics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE Implementation\n",
    "\n",
    "ROUGE originally started as a set of Perl scripts and has been ported into many languages since. We're going to use a Python implementation from [Google Research](https://github.com/google-research/google-research/tree/master/rouge) here that we've tweaked slightly.\n",
    "\n",
    "It's not easily installed as a package, so it's included here. Feel free to skip past it if you're not interested in the details. See you on the other side. 👋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import collections\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"A library for tokenizing text.\"\"\"\n",
    "# Pre-compile regexes that are use often\n",
    "NON_ALPHANUM_PATTERN = r\"[^a-z0-9]+\"\n",
    "NON_ALPHANUM_RE = re.compile(NON_ALPHANUM_PATTERN)\n",
    "SPACES_PATTERN = r\"\\s+\"\n",
    "SPACES_RE = re.compile(SPACES_PATTERN)\n",
    "VALID_TOKEN_PATTERN = r\"^[a-z0-9]+$\"\n",
    "VALID_TOKEN_RE = re.compile(VALID_TOKEN_PATTERN)\n",
    "\n",
    "\n",
    "def tokenize(text, stemmer):\n",
    "    \"\"\"Tokenize input text into a list of tokens.\n",
    "\n",
    "    This approach aims to replicate the approach taken by Chin-Yew Lin in\n",
    "    the original ROUGE implementation.\n",
    "\n",
    "    Args:\n",
    "      text: A text blob to tokenize.\n",
    "      stemmer: An optional stemmer.\n",
    "\n",
    "    Returns:\n",
    "      A list of string tokens extracted from input text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert everything to lowercase.\n",
    "    text = text.lower()\n",
    "    # Replace any non-alpha-numeric characters with spaces.\n",
    "    text = NON_ALPHANUM_RE.sub(\" \", str(text))\n",
    "\n",
    "    tokens = SPACES_RE.split(text)\n",
    "    if stemmer:\n",
    "        # Only stem words more than 3 characters long.\n",
    "        tokens = [str(stemmer.stem(x)) if len(x) > 3 else x for x in tokens]\n",
    "\n",
    "    # One final check to drop any empty or invalid tokens.\n",
    "    tokens = [x for x in tokens if VALID_TOKEN_RE.match(x)]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\"\"\"Library containing Tokenizer definitions.\n",
    "\n",
    "The RougeScorer class can be instantiated with the tokenizers defined here. New\n",
    "tokenizers can be defined by creating a subclass of the Tokenizer abstract class\n",
    "and overriding the tokenize() method.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Tokenizer(abc.ABC):\n",
    "    \"\"\"Abstract base class for a tokenizer.\n",
    "\n",
    "    Subclasses of Tokenizer must implement the tokenize() method.\n",
    "    \"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def tokenize(self, text):\n",
    "        raise NotImplementedError(\"Tokenizer must override tokenize() method\")\n",
    "\n",
    "\n",
    "class DefaultTokenizer(Tokenizer):\n",
    "    \"\"\"Default tokenizer which tokenizes on whitespace.\"\"\"\n",
    "\n",
    "    def __init__(self, use_stemmer=False):\n",
    "        \"\"\"Constructor for DefaultTokenizer.\n",
    "\n",
    "        Args:\n",
    "          use_stemmer: boolean indicating whether to use stemming.\n",
    "          This is set to False by default as we don't use stemming in our implementation\n",
    "          to avoid the NLTK dependency.\n",
    "        \"\"\"\n",
    "        # Always set _stemmer to None since we don't use the NLTK dependency\n",
    "        self._stemmer = None\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return tokenize(text, self._stemmer)\n",
    "\n",
    "\n",
    "\"\"\"Computes rouge scores between two text blobs.\n",
    "\n",
    "This implementation comes from: https://github.com/google-research/google-research/tree/master/rouge\n",
    "\n",
    "Implementation replicates the functionality in the original ROUGE package. See:\n",
    "\n",
    "Lin, Chin-Yew. ROUGE: a Package for Automatic Evaluation of Summaries. In\n",
    "Proceedings of the Workshop on Text Summarization Branches Out (WAS 2004),\n",
    "Barcelona, Spain, July 25 - 26, 2004.\n",
    "\n",
    "Default options are equivalent to running:\n",
    "ROUGE-1.5.5.pl -e data -n 2 -a settings.xml\n",
    "\n",
    "Or with use_stemmer=True:\n",
    "ROUGE-1.5.5.pl -m -e data -n 2 -a settings.xml\n",
    "\n",
    "In these examples settings.xml lists input files and formats.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Score(collections.namedtuple(\"Score\", [\"precision\", \"recall\", \"fmeasure\"])):\n",
    "    \"\"\"Tuple containing precision, recall, and f-measure values.\"\"\"\n",
    "\n",
    "\n",
    "class BaseScorer(object, metaclass=abc.ABCMeta):\n",
    "    \"\"\"Base class for Scorer objects.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def score(self, target, prediction):\n",
    "        \"\"\"Calculates score between the target and prediction.\n",
    "\n",
    "        Args:\n",
    "          target: Text containing the target (ground truth) text.\n",
    "          prediction: Text containing the predicted text.\n",
    "\n",
    "        Returns:\n",
    "          A dict mapping each score_type (string) to Score object.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "class RougeScorer(BaseScorer):\n",
    "    \"\"\"Calculate rouges scores between two blobs of text.\n",
    "\n",
    "    Sample usage:\n",
    "      scorer = RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "      scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "                            'The quick brown dog jumps on the log.')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rouge_types, tokenizer=None):\n",
    "        \"\"\"Initializes a new RougeScorer.\n",
    "\n",
    "        Valid rouge types that can be computed are:\n",
    "          rougen (e.g. rouge1, rouge2): n-gram based scoring.\n",
    "          rougeL: Longest common subsequence based scoring.\n",
    "\n",
    "        Args:\n",
    "          rouge_types: A list of rouge types to calculate.\n",
    "          use_stemmer: Bool indicating whether Porter stemmer should be used to\n",
    "            strip word suffixes to improve matching. This arg is used in the\n",
    "            DefaultTokenizer, but other tokenizers might or might not choose to\n",
    "            use this.\n",
    "          split_summaries: whether to add newlines between sentences for rougeLsum\n",
    "          tokenizer: Tokenizer object which has a tokenize() method.\n",
    "        Returns:\n",
    "          A dict mapping rouge types to Score tuples.\n",
    "        \"\"\"\n",
    "        use_stemmer = False\n",
    "        split_summaries = (False,)\n",
    "        self.rouge_types = rouge_types\n",
    "        if tokenizer:\n",
    "            self._tokenizer = tokenizer\n",
    "        else:\n",
    "            self._tokenizer = DefaultTokenizer(use_stemmer)\n",
    "\n",
    "        self._split_summaries = split_summaries\n",
    "\n",
    "    def score_multi(self, targets, prediction):\n",
    "        \"\"\"Calculates rouge scores between targets and prediction.\n",
    "\n",
    "        The target with the maximum f-measure is used for the final score for\n",
    "        each score type..\n",
    "\n",
    "        Args:\n",
    "          targets: list of texts containing the targets\n",
    "          prediction: Text containing the predicted text.\n",
    "        Returns:\n",
    "          A dict mapping each rouge type to a Score object.\n",
    "        Raises:\n",
    "          ValueError: If an invalid rouge type is encountered.\n",
    "        \"\"\"\n",
    "        score_dicts = [self.score(t, prediction) for t in targets]\n",
    "        max_score = {}\n",
    "        for k in self.rouge_types:\n",
    "            index = np.argmax([s[k].fmeasure for s in score_dicts])\n",
    "            max_score[k] = score_dicts[index][k]\n",
    "\n",
    "        return max_score\n",
    "\n",
    "    def score(self, target, prediction):\n",
    "        \"\"\"Calculates rouge scores between the target and prediction.\n",
    "\n",
    "        Args:\n",
    "          target: Text containing the target (ground truth) text\n",
    "          prediction: Text containing the predicted text\n",
    "        Returns:\n",
    "          A dict mapping each rouge type to a Score object.\n",
    "        Raises:\n",
    "          ValueError: If an invalid rouge type is encountered.\n",
    "        \"\"\"\n",
    "        # Pre-compute target tokens and prediction tokens for use by different\n",
    "        # types, except if only \"rougeLsum\" is requested.\n",
    "        if len(self.rouge_types) == 1 and self.rouge_types[0] == \"rougeLsum\":\n",
    "            target_tokens = None\n",
    "            prediction_tokens = None\n",
    "        else:\n",
    "            target_tokens = self._tokenizer.tokenize(target)\n",
    "            prediction_tokens = self._tokenizer.tokenize(prediction)\n",
    "        result = {}\n",
    "\n",
    "        for rouge_type in self.rouge_types:\n",
    "            if rouge_type == \"rougeL\":\n",
    "                # Rouge from longest common subsequences.\n",
    "                scores = _score_lcs(target_tokens, prediction_tokens)\n",
    "            elif rouge_type == \"rougeLsum\":\n",
    "                # Note: Does not support multi-line text.\n",
    "                def get_sents(text):\n",
    "                    # Assume sentences are separated by newline.\n",
    "                    sents = str(text).split(\"\\n\")\n",
    "                    sents = [x for x in sents if len(x)]\n",
    "                    return sents\n",
    "\n",
    "                target_tokens_list = [\n",
    "                    self._tokenizer.tokenize(s) for s in get_sents(target)\n",
    "                ]\n",
    "                prediction_tokens_list = [\n",
    "                    self._tokenizer.tokenize(s) for s in get_sents(prediction)\n",
    "                ]\n",
    "\n",
    "                scores = _summary_level_lcs(target_tokens_list, prediction_tokens_list)\n",
    "            elif re.match(r\"rouge[0-9]$\", str(rouge_type)):\n",
    "                # Rouge from n-grams.\n",
    "                n = int(rouge_type[5:])\n",
    "                if n <= 0:\n",
    "                    raise ValueError(\"rougen requires positive n: %s\" % rouge_type)\n",
    "                target_ngrams = _create_ngrams(target_tokens, n)\n",
    "                prediction_ngrams = _create_ngrams(prediction_tokens, n)\n",
    "                scores = _score_ngrams(target_ngrams, prediction_ngrams)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid rouge type: %s\" % rouge_type)\n",
    "            result[rouge_type] = scores\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def _create_ngrams(tokens, n):\n",
    "    \"\"\"Creates ngrams from the given list of tokens.\n",
    "\n",
    "    Args:\n",
    "      tokens: A list of tokens from which ngrams are created.\n",
    "      n: Number of tokens to use, e.g. 2 for bigrams.\n",
    "    Returns:\n",
    "      A dictionary mapping each bigram to the number of occurrences.\n",
    "    \"\"\"\n",
    "\n",
    "    ngrams = collections.Counter()\n",
    "    for ngram in (tuple(tokens[i : i + n]) for i in range(len(tokens) - n + 1)):\n",
    "        ngrams[ngram] += 1\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def _score_lcs(target_tokens, prediction_tokens):\n",
    "    \"\"\"Computes LCS (Longest Common Subsequence) rouge scores.\n",
    "\n",
    "    Args:\n",
    "      target_tokens: Tokens from the target text.\n",
    "      prediction_tokens: Tokens from the predicted text.\n",
    "    Returns:\n",
    "      A Score object containing computed scores.\n",
    "    \"\"\"\n",
    "\n",
    "    if not target_tokens or not prediction_tokens:\n",
    "        return Score(precision=0, recall=0, fmeasure=0)\n",
    "\n",
    "    # Compute length of LCS from the bottom up in a table (DP appproach).\n",
    "    lcs_table = _lcs_table(target_tokens, prediction_tokens)\n",
    "    lcs_length = lcs_table[-1][-1]\n",
    "\n",
    "    precision = lcs_length / len(prediction_tokens)\n",
    "    recall = lcs_length / len(target_tokens)\n",
    "    fmeasure = _fmeasure(precision, recall)\n",
    "\n",
    "    return Score(precision=precision, recall=recall, fmeasure=fmeasure)\n",
    "\n",
    "\n",
    "def _lcs_table(ref, can):\n",
    "    \"\"\"Create 2-d LCS score table.\"\"\"\n",
    "    rows = len(ref)\n",
    "    cols = len(can)\n",
    "    lcs_table = [[0] * (cols + 1) for _ in range(rows + 1)]\n",
    "    for i in range(1, rows + 1):\n",
    "        for j in range(1, cols + 1):\n",
    "            if ref[i - 1] == can[j - 1]:\n",
    "                lcs_table[i][j] = lcs_table[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                lcs_table[i][j] = max(lcs_table[i - 1][j], lcs_table[i][j - 1])\n",
    "    return lcs_table\n",
    "\n",
    "\n",
    "def _backtrack_norec(t, ref, can):\n",
    "    \"\"\"Read out LCS.\"\"\"\n",
    "    i = len(ref)\n",
    "    j = len(can)\n",
    "    lcs = []\n",
    "    while i > 0 and j > 0:\n",
    "        if ref[i - 1] == can[j - 1]:\n",
    "            lcs.insert(0, i - 1)\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif t[i][j - 1] > t[i - 1][j]:\n",
    "            j -= 1\n",
    "        else:\n",
    "            i -= 1\n",
    "    return lcs\n",
    "\n",
    "\n",
    "def _summary_level_lcs(ref_sent, can_sent):\n",
    "    \"\"\"ROUGE: Summary-level LCS, section 3.2 in ROUGE paper.\n",
    "\n",
    "    Args:\n",
    "      ref_sent: list of tokenized reference sentences\n",
    "      can_sent: list of tokenized candidate sentences\n",
    "\n",
    "    Returns:\n",
    "      summary level ROUGE score\n",
    "    \"\"\"\n",
    "    if not ref_sent or not can_sent:\n",
    "        return Score(precision=0, recall=0, fmeasure=0)\n",
    "\n",
    "    m = sum(map(len, ref_sent))\n",
    "    n = sum(map(len, can_sent))\n",
    "    if not n or not m:\n",
    "        return Score(precision=0, recall=0, fmeasure=0)\n",
    "\n",
    "    # get token counts to prevent double counting\n",
    "    token_cnts_r = collections.Counter()\n",
    "    token_cnts_c = collections.Counter()\n",
    "    for s in ref_sent:\n",
    "        # s is a list of tokens\n",
    "        token_cnts_r.update(s)\n",
    "    for s in can_sent:\n",
    "        token_cnts_c.update(s)\n",
    "\n",
    "    hits = 0\n",
    "    for r in ref_sent:\n",
    "        lcs = _union_lcs(r, can_sent)\n",
    "        # Prevent double-counting:\n",
    "        # The paper describes just computing hits += len(_union_lcs()),\n",
    "        # but the implementation prevents double counting. We also\n",
    "        # implement this as in version 1.5.5.\n",
    "        for t in lcs:\n",
    "            if token_cnts_c[t] > 0 and token_cnts_r[t] > 0:\n",
    "                hits += 1\n",
    "                token_cnts_c[t] -= 1\n",
    "                token_cnts_r[t] -= 1\n",
    "\n",
    "    recall = hits / m\n",
    "    precision = hits / n\n",
    "    fmeasure = _fmeasure(precision, recall)\n",
    "    return Score(precision=precision, recall=recall, fmeasure=fmeasure)\n",
    "\n",
    "\n",
    "def _union_lcs(ref, c_list):\n",
    "    \"\"\"Find union LCS between a ref sentence and list of candidate sentences.\n",
    "\n",
    "    Args:\n",
    "      ref: list of tokens\n",
    "      c_list: list of list of indices for LCS into reference summary\n",
    "\n",
    "    Returns:\n",
    "      List of tokens in ref representing union LCS.\n",
    "    \"\"\"\n",
    "    lcs_list = [lcs_ind(ref, c) for c in c_list]\n",
    "    return [ref[i] for i in _find_union(lcs_list)]\n",
    "\n",
    "\n",
    "def _find_union(lcs_list):\n",
    "    \"\"\"Finds union LCS given a list of LCS.\"\"\"\n",
    "    return sorted(list(set().union(*lcs_list)))\n",
    "\n",
    "\n",
    "def lcs_ind(ref, can):\n",
    "    \"\"\"Returns one of the longest lcs.\"\"\"\n",
    "    t = _lcs_table(ref, can)\n",
    "    return _backtrack_norec(t, ref, can)\n",
    "\n",
    "\n",
    "def _score_ngrams(target_ngrams, prediction_ngrams):\n",
    "    \"\"\"Compute n-gram based rouge scores.\n",
    "\n",
    "    Args:\n",
    "      target_ngrams: A Counter object mapping each ngram to number of\n",
    "        occurrences for the target text.\n",
    "      prediction_ngrams: A Counter object mapping each ngram to number of\n",
    "        occurrences for the prediction text.\n",
    "    Returns:\n",
    "      A Score object containing computed scores.\n",
    "    \"\"\"\n",
    "\n",
    "    intersection_ngrams_count = 0\n",
    "    for ngram in target_ngrams:\n",
    "        intersection_ngrams_count += min(target_ngrams[ngram], prediction_ngrams[ngram])\n",
    "    target_ngrams_count = sum(target_ngrams.values())\n",
    "    prediction_ngrams_count = sum(prediction_ngrams.values())\n",
    "\n",
    "    precision = intersection_ngrams_count / max(prediction_ngrams_count, 1)\n",
    "    recall = intersection_ngrams_count / max(target_ngrams_count, 1)\n",
    "    fmeasure = _fmeasure(precision, recall)\n",
    "\n",
    "    return Score(precision=precision, recall=recall, fmeasure=fmeasure)\n",
    "\n",
    "\n",
    "def _fmeasure(precision, recall):\n",
    "    \"\"\"Computes f-measure given precision and recall values.\"\"\"\n",
    "\n",
    "    if precision + recall > 0:\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring\n",
    "\n",
    "Welcome back!\n",
    "\n",
    "Now that've got that implementation, time to make use of all that mystical splitting we did earlier. I'll let you in on a little secret: because we're not \"training\" a model in the conventional sense (*yet*), it's a bit harder to overfit, so the validation split is slightly less important. Our only real thing to tweak is the prompt, and since we're doing it manually, it would take a lot of work to find a prompt that *only* improved performance on the training set.\n",
    "\n",
    "With that said, we should still follow best practice, and it's good we have a validation split because we may want to take an approach in the future that will have a higher propensity to overfit.\n",
    "\n",
    "So let's do two things:\n",
    "1. See how we're doing on the **training** set.\n",
    "2. See how we're doing on the **validation** set.\n",
    "\n",
    "Ideally moving forward, we'd mostly be looking at the training set and only occasionally looking at the validation set, but it'll be a good check of our sanity to see if the scores for training and validation look the same.\n",
    "\n",
    "The `RougeScorer` allows for a number of different ROUGE metrics and outputs precision, recall, and F1 (\"F-measure\"), but let's simplify and just look at F1 of ROUGE-2 since that's what we're using for the competition leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = RougeScorer([\"rouge2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scores_to_preds(preds: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Score every summary in a dataframe and add a new score column\"\"\"\n",
    "    scores = {}\n",
    "    for id, row in preds.iterrows():\n",
    "        scores[id] = scorer.score(row[\"summary\"], row[\"my_summary\"])[\"rouge2\"].fmeasure\n",
    "    return preds.assign(rouge2=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score on the training split: 0.0578.\n",
      "Current score on the validation split: 0.0595.\n"
     ]
    }
   ],
   "source": [
    "train_preds = add_scores_to_preds(train_preds)\n",
    "print(f\"Current score on the training split: {train_preds.rouge2.mean():.4f}.\")\n",
    "\n",
    "val_preds = add_scores_to_preds(val_preds)\n",
    "print(f\"Current score on the validation split: {val_preds.rouge2.mean():.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so this is a good news-bad news situation. The **good news**: the training and validation scores are really close to one another! We're not overfit to training (which would be surprising), and the datasets must be pretty similar.\n",
    "\n",
    "The **bad news**: these scores are *bad*. On a scale from 0 to 100, we're getting a five and a half.\n",
    "\n",
    "Hurray, **opportunity**! **Room to grow**! 🫠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is probably to beat this benchmark, and if we left things there, this might be a little too easy to beat. Let's tweak a couple things:\n",
    "1. Summaries aren't usually one sentence.\n",
    "2. We don't need to hear \"Here's a one-sentence summary\" every time. That's certainly not doing our scores any favors.\n",
    "\n",
    "We'll write a new prompt (and a new function around that prompt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractize(doc: str, max_doc_chars: int = 7_000) -> str:\n",
    "    \"\"\"Write an abstract for (part of) a document\"\"\"\n",
    "    prompt_template = \"Can you please write a one-paragraph academic abstract of the following document?\\n\\n{doc}\\n\\nReturn only your paragraph with no additional text.\"\n",
    "    resp, completion = ask_llm(prompt_template.format(doc=doc[:max_doc_chars]))\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81c772e5e1749ff8580ce9b11e58b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{827: 'Suzuki’s early engagement with anime and film, spurred by his childhood fascination with these media, ultimately shaped his career trajectory within the industry. Initially working as an editor at Tokuma Shoten, he developed a keen understanding of manga and film production, fostering connections with key figures like Hideo Ogata and Miyazaki. Recognizing the potential of anime, Suzuki spearheaded the creation of Animage, a magazine dedicated to the burgeoning genre, and subsequently played a pivotal role in the development of Studio Ghibli through his insights and influence, demonstrating the profound impact of his initial observations on the establishment of this iconic animation studio.',\n",
       " 166: 'The present study examines the quality of the English collaborative translation of Rajaa Alsanea’s novel, *Girls of Riyadh*, focusing on the impact of the self-translator’s alterations and the co-translator’s approach. The translation’s apparent tension between the self-translator’s stylistic choices and the target culture, as highlighted by the original text, presents a challenge for accurate rendition. This research investigates how the literal and functional approaches to translation were employed in the collaborative process, specifically analyzing the impact of the self-translator’s changes on the novel’s linguistic, cultural, and stylistic elements, ultimately examining the evident tension between the two translators’ distinct methodologies and the resulting implications for the translation’s authenticity.',\n",
       " 170: 'The pervasive and increasingly accelerating stigmatization of ADHD, fueled by the recent rise in global prevalence and the continued perpetuation of negative perceptions, presents a significant challenge to the well-being of individuals with the condition.  Research indicates that this stigma, manifesting through labeling individuals as “impolite, unreliable, or weak,” contributes to self-hatred, refusal to seek treatment, and increased psychological distress, impacting long-term outcomes across various domains like addiction, mental health, and life satisfaction.  Furthermore, the lack of research focusing on the cultural context of ADHD within Taiwan, where stigma disproportionately affects the adult population, highlights a need for culturally sensitive interventions to mitigate the harmful consequences of this pervasive societal misperception and improve the lives of those with this condition.',\n",
       " 328: 'The paper’s central focus is to understand how current research priorities, particularly in health, align with societal needs and demands, as evidenced by the evolving landscape of mission-oriented innovation policies. It investigates whether current research investments are adequately addressing the pressing health challenges of cardiometabolic and mental health, contrasting these priorities with stakeholder perceptions of desired health interventions. The study aims to identify knowledge gaps and opportunities within these two areas, ultimately supporting Vinnova’s reflection on funding priorities and fostering a more reflexive and evaluative approach to research to better support health interventions and societal well-being, potentially requiring a broader institutional shift in research organization – as suggested by literature on transformative change.',\n",
       " 347: 'The present study addresses the significant writing difficulties experienced by ESL students at the college IEP101 program, where many students struggled with coherent and accurate writing due to lack of support and preparation. Literature indicates that effective second language (L2) writing necessitates cohesive, well-structured, and adequately organized text, aligning with principles of scaffolding (Choi &amp; Wong, 2018; Fareed et al., 2016; Piamsai, 2017). This research sought to answer three key questions: 1) What writing challenges did students face? 2) How does instructional scaffolding impact student writing performance? The study utilized a constructivist lens, emphasizing the collaborative construction of knowledge within a Vygotsky-inspired classroom environment, where students benefit from peer support and guidance to achieve mastery, as supported by the zone of proximal development (ZPD) theory.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_summary = predict_on_dataset(train, max_docs=5, summarize_fn=abstractize)\n",
    "id_to_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better!  ...  Better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction *Redux*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e473ba1ca0f401a9dd2e6b633290d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score on the training split: 0.0798.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb2085716904a21987e10b7542cdb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score on the validation split: 0.0779.\n"
     ]
    }
   ],
   "source": [
    "train_id_to_summary = predict_on_dataset(train, summarize_fn=abstractize)\n",
    "train_preds = train.assign(my_summary=train_id_to_summary)\n",
    "train_preds = add_scores_to_preds(train_preds)\n",
    "print(f\"Current score on the training split: {train_preds.rouge2.mean():.4f}.\")\n",
    "\n",
    "val_id_to_summary = predict_on_dataset(validation, summarize_fn=abstractize)\n",
    "val_preds = validation.assign(my_summary=val_id_to_summary)\n",
    "val_preds = add_scores_to_preds(val_preds)\n",
    "print(f\"Current score on the validation split: {val_preds.rouge2.mean():.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better!\n",
    "\n",
    "(Still bad.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Submission\n",
    "\n",
    "Now we just have to get things into the right format!\n",
    "\n",
    "As a reminder, this test data and the submission format comes from the [data download page](https://www.drivendata.org/competitions/297/competition-llm-doc-summarization/data/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>## Introduction\\n\\n\\nGender disparities persis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>## Introduction\\n\\n\\nOne of humanity’s greates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>## Introduction\\n\\n\\nHow do workers get attach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>## BETWEEN INDEXES AND SYMBOLS: AN EXPRESSION ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>## The Evolution of Environmental and Climate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>## 1 Introduction\\n\\n\\nLife expectancy has con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>## INTRODUCTION\\n\\n\\nThere is growing evidence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>## 1. Introduction\\n\\n\\nSchool achievement is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>## BACKGROUND AND EXPECTATIONS\\n\\n\\n\\n## Polit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>## 1 Introduction\\n\\n\\nUS higher education is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text\n",
       "paper_id                                                   \n",
       "1000      ## Introduction\\n\\n\\nGender disparities persis...\n",
       "1001      ## Introduction\\n\\n\\nOne of humanity’s greates...\n",
       "1002      ## Introduction\\n\\n\\nHow do workers get attach...\n",
       "1003      ## BETWEEN INDEXES AND SYMBOLS: AN EXPRESSION ...\n",
       "1004      ## The Evolution of Environmental and Climate ...\n",
       "...                                                     ...\n",
       "1340      ## 1 Introduction\\n\\n\\nLife expectancy has con...\n",
       "1341      ## INTRODUCTION\\n\\n\\nThere is growing evidence...\n",
       "1342      ## 1. Introduction\\n\\n\\nSchool achievement is ...\n",
       "1343      ## BACKGROUND AND EXPECTATIONS\\n\\n\\n\\n## Polit...\n",
       "1344      ## 1 Introduction\\n\\n\\nUS higher education is ...\n",
       "\n",
       "[345 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    DATA_DIR / \"test_features.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af3da9d1c5a44d29dd7bb3c2ad7f1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>## Introduction\\n\\n\\nGender disparities persis...</td>\n",
       "      <td>Gender ideology, as a heuristic tool, represen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>## Introduction\\n\\n\\nOne of humanity’s greates...</td>\n",
       "      <td>The theory of planned behaviour (TPB) – a corn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>## Introduction\\n\\n\\nHow do workers get attach...</td>\n",
       "      <td>The study investigates the construction of wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>## BETWEEN INDEXES AND SYMBOLS: AN EXPRESSION ...</td>\n",
       "      <td>The fragmented nature of social interaction, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>## The Evolution of Environmental and Climate ...</td>\n",
       "      <td>The evolving relationship between family dynam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>## 1 Introduction\\n\\n\\nLife expectancy has con...</td>\n",
       "      <td>The ongoing focus on healthy life expectancy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>## INTRODUCTION\\n\\n\\nThere is growing evidence...</td>\n",
       "      <td>Experience sampling techniques, a growing meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>## 1. Introduction\\n\\n\\nSchool achievement is ...</td>\n",
       "      <td>The document highlights a significant disparit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>## BACKGROUND AND EXPECTATIONS\\n\\n\\n\\n## Polit...</td>\n",
       "      <td>Research in political science and sociology re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>## 1 Introduction\\n\\n\\nUS higher education is ...</td>\n",
       "      <td>The growing body of research on college admiss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  \\\n",
       "paper_id                                                      \n",
       "1000      ## Introduction\\n\\n\\nGender disparities persis...   \n",
       "1001      ## Introduction\\n\\n\\nOne of humanity’s greates...   \n",
       "1002      ## Introduction\\n\\n\\nHow do workers get attach...   \n",
       "1003      ## BETWEEN INDEXES AND SYMBOLS: AN EXPRESSION ...   \n",
       "1004      ## The Evolution of Environmental and Climate ...   \n",
       "...                                                     ...   \n",
       "1340      ## 1 Introduction\\n\\n\\nLife expectancy has con...   \n",
       "1341      ## INTRODUCTION\\n\\n\\nThere is growing evidence...   \n",
       "1342      ## 1. Introduction\\n\\n\\nSchool achievement is ...   \n",
       "1343      ## BACKGROUND AND EXPECTATIONS\\n\\n\\n\\n## Polit...   \n",
       "1344      ## 1 Introduction\\n\\n\\nUS higher education is ...   \n",
       "\n",
       "                                                    summary  \n",
       "paper_id                                                     \n",
       "1000      Gender ideology, as a heuristic tool, represen...  \n",
       "1001      The theory of planned behaviour (TPB) – a corn...  \n",
       "1002      The study investigates the construction of wor...  \n",
       "1003      The fragmented nature of social interaction, a...  \n",
       "1004      The evolving relationship between family dynam...  \n",
       "...                                                     ...  \n",
       "1340      The ongoing focus on healthy life expectancy, ...  \n",
       "1341      Experience sampling techniques, a growing meth...  \n",
       "1342      The document highlights a significant disparit...  \n",
       "1343      Research in political science and sociology re...  \n",
       "1344      The growing body of research on college admiss...  \n",
       "\n",
       "[345 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id_to_summary = predict_on_dataset(test, summarize_fn=abstractize)\n",
    "test_preds = test.assign(summary=test_id_to_summary)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.drop(columns=[\"text\"]).to_csv(\"submission.csv\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's [submit our summaries](https://www.drivendata.org/competitions/297/whats-up-docs/submissions/) to get on the leaderboard.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "That's right between our training and validation scores, so things look good! (But the score is still bad.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "Whew! Was that a lot? That felt like a lot. Congrats on making it through!\n",
    "\n",
    "Maybe it's more like, \"Congrats on making it up!\" because you've made it through the guided portion of the hike, and now you're striking out on your own - **onwards and upwards!**\n",
    "\n",
    "Wait, didn't I start out with a swimming metaphor about diving in or something? Maybe you've climbed to the top of the water slide? I don't know - I do data science, I'm not a metaphorologist.\n",
    "\n",
    "Anyway, we hope you learned something! These tools are fun and interesting and maybe useful, so **go build!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encore\n",
    "\n",
    "I know we said the guided portion is over, but we should at least point out which way is North. Here are some things that you could try that might improve what we're built here:\n",
    "\n",
    "* **Handle the context window better.** We're only summarizing the first tiny portion of the documents right now because our context window is only 2,048 tokens. You could:\n",
    "  - Make the context window bigger using [Ollama settings](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-specify-the-context-window-size)\n",
    "  - Make the context window even bigger using a [different model](https://ollama.com/library/gemma3:4b)\n",
    "  - Look up and implement \"recursive summarization\"\n",
    "* **Optimize the prompt.** You could:\n",
    "  - Just try a bunch of different prompts to get a feel for what works\n",
    "  - Script that process\n",
    "  - Look up \"few-shot prompting\"\n",
    "  - Read about \"prompt optimization\"\n",
    "  - Dive into existing tools, e.g. [DSPy](https://github.com/stanfordnlp/dspy)\n",
    "* **Try smarter models.** While the model we're using here is state-of-the-art for its size, there are bigger models that are better. You might need to use a model hosted elsewhere.\n",
    "* **Think about ethics.** This won't necessarily get you *leaderboard* points (though some things here will), but it will absolutely get you *karma* points. Does this benchmark do worse on some kinds of social science papers relative to others? Do your *prompts* induce biases in the model? What would that mean practically? Might different models be biased toward different kinds of errors? Can you use that to your advantage? How much CO2-equivalent is being released into the atmosphere by running these models? How might you limit it so that you can experiment without cooking your grandchildren (any more than flying in a plane might)?\n",
    "* **Exploit the dataset.** Often in data science projects, getting to know the data very, very well pays off in surprising ways. For example, do any of the docs in this dataset contain the full abstract verbatim? Can you use that? This will only get you so far, and in an ideal world you wouldn't find stuff like this, but see the point below.\n",
    "* **Think hard about the metric.** What does this metric reward and penalize? What's the dumbest way to write a summary that would get you the highest score on the metric?\n",
    "* **Think hard about the problem.** Good summaries come in many different forms. A 50 page report might have a 2 page Executive Summary while the headline of a news article might also be considered a summary. That means you might look at some of the documents in this dataset and read some of your generated summaries and think, \"That's a great summary!\" then submit it and get a terrible score. *You might still be right.* It can be frustrating to read your predictions, think they're very good, and still score badly. I mean, you're solving the problem, shouldn't your score reflect that? The larger task is to create a great summary, but the immediate task is to generate summary text that *looks like the text in the test dataset.* (It's our [DrivenData's] job to make sure that a great solution on the test dataset translates into a great solution in the larger context. If you think we might have missed something, or if you have a question about it, [reach out](https://community.drivendata.org/c/whats-up-docs/106)! We're all humans trying to do the best we can with our flawed, juicy hardware.) In this competition, the summaries are academic abstracts, so your summaries should look like those. How long are abstracts, typically? What kind of language do they use? When a human is writing the abstract (if a human is writing the abstract), which parts of the larger document do they typically pull from?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition-world-bank-jff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
