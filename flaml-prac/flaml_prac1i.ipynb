{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b310c61",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e980ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import math\n",
    "import numpy as np \n",
    "from colorama import Fore, Style, init;\n",
    "import optuna\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Model and Utiliz\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score , train_test_split\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Remove Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "# Set the option to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Import The AUTO_ML\n",
    "from flaml import AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f73f23",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b6850",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['#FFFF00','#2DA8D8']\n",
    "\n",
    "# Intlize Colors\n",
    "HEAD = '#FFFF00'\n",
    "TEXT = '#2DA8D8'\n",
    "\n",
    "# Text Styling\n",
    "def print_unique_header(heading,heading_color=HEAD, text_color=TEXT):\n",
    "    def color_text(text, hex_color):\n",
    "        # Convert hex color to RGB\n",
    "        rgb = tuple(int(hex_color[i:i+2], 16) for i in (1, 3, 5))\n",
    "        # Apply ANSI escape code for the given RGB color\n",
    "        return f\"\\033[38;2;{rgb[0]};{rgb[1]};{rgb[2]}m{text}\\033[0m\"\n",
    "\n",
    "    bright = \"\\033[1m\"\n",
    "    reset = \"\\033[0m\"\n",
    "\n",
    "    total_width = len(heading) + 20\n",
    "    left_space = (total_width - len(heading)) // 2\n",
    "    right_space = total_width - len(heading) - left_space\n",
    "\n",
    "    print(\"\\n\" + color_text(\"╭\" + \"─\" * total_width + \"╮\", heading_color)) \n",
    "    print(color_text(f\"│{' ' * left_space}{'▲'}{' ' * right_space}\", heading_color) + reset)\n",
    "    print(color_text(f\"│{' ' * left_space}\", heading_color) + color_text(heading, text_color) + color_text(f\"{' ' * right_space}│\", heading_color) + reset)\n",
    "    print(color_text(f\"│{' ' * left_space}{'▼'}{' ' * right_space}\", heading_color) + reset)\n",
    "    print(color_text(\"╰\" + \"─\" * total_width + \"╯\", heading_color))\n",
    "\n",
    "def print_boxed_zigzag_heading(heading, heading_color=HEAD, text_color=TEXT):\n",
    "    def color_text(text, hex_color):\n",
    "        # Convert hex color to RGB\n",
    "        rgb = tuple(int(hex_color[i:i+2], 16) for i in (1, 3, 5))\n",
    "        # Apply ANSI escape code for the given RGB color\n",
    "        return f\"\\033[38;2;{rgb[0]};{rgb[1]};{rgb[2]}m{text}\\033[0m\"\n",
    "\n",
    "    bright = \"\\033[1m\"\n",
    "    reset = \"\\033[0m\"\n",
    "\n",
    "    heading_color_code = color_text(\"╭\" + \"─\" * (len(heading) + 20) + \"╮\", heading_color)\n",
    "    \n",
    "    print(\"\\n\" + heading_color_code)\n",
    "    words = heading.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if i == len(words) - 1:\n",
    "            print(f\"{color_text(f'│ {word} │', text_color)}{reset}\")\n",
    "        else:\n",
    "            print(f\"{color_text(f'│ {word}', text_color)}{reset}\", end=\" \")\n",
    "    \n",
    "    print(color_text(\"╰\" + \"─\" * (len(heading) + 20) + \"╯\", heading_color))\n",
    "    \n",
    "def prinT(text, hex_color=TEXT):\n",
    "    # Convert hex color to RGB\n",
    "    rgb = tuple(int(hex_color[i:i+2], 16) for i in (1, 3, 5))\n",
    "    # Apply ANSI escape code for the given RGB color\n",
    "    colored_text = f\"\\033[38;2;{rgb[0]};{rgb[1]};{rgb[2]}m{text}\\033[0m\"\n",
    "    print(colored_text)\n",
    "\n",
    "print_unique_header(\"Setup Intilized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac44fd6",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a9949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Submission Data \n",
    "d_s = pd.read_csv('/kaggle/input/playground-series-s4e6/sample_submission.csv')\n",
    "# Load test Data \n",
    "te_d = pd.read_csv('/kaggle/input/playground-series-s4e6/test.csv')\n",
    "#Train Data \n",
    "tr_d = pd.read_csv('/kaggle/input/playground-series-s4e6/train.csv')\n",
    "\n",
    "# Original Data \n",
    "O_D = pd.read_csv(\"/kaggle/input/playgrounds4e06originaldata/original.csv\")\n",
    "\n",
    "# Dropping Id from  Train \n",
    "tr_d.drop(columns=['id'], inplace=True)\n",
    "te_d.drop(columns=['id'], inplace=True)\n",
    "O_D.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Concat \n",
    "tr_d = pd.concat(objs=[tr_d, O_D])\n",
    "\n",
    "# Drop Irreleveant \n",
    "tr_d.drop(labels='Daytime/evening attendance\\t', axis=1, inplace=True)\n",
    "# Fill Null Values \n",
    "most_frequent = tr_d['Daytime/evening attendance'].mode()[0]\n",
    "tr_d['Daytime/evening attendance'].fillna(most_frequent, inplace=True)\n",
    "\n",
    "# Overview Fucntion\n",
    "def print_boxed_blue_heading(heading):\n",
    "    gradient = [Fore.BLUE, Fore.CYAN, Fore.GREEN, Fore.YELLOW, Fore.RED, Fore.MAGENTA]\n",
    "    print(\"\\n\" + \"=\" * (len(heading) + 4))\n",
    "    words = heading.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if i == len(words) - 1:\n",
    "            print(f\"| {gradient[len(word) % len(gradient)] + word + Style.RESET_ALL} |\")\n",
    "        else:\n",
    "            print(f\"| {gradient[len(word) % len(gradient)] + word + Style.RESET_ALL}\", end=\" \")\n",
    "    print(\"=\" * (len(heading) + 4))\n",
    "print_unique_header('Dat Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psod_outlier_detection_removal(data, n_components=2, threshold=3):\n",
    "\n",
    "    # Step 1: Apply PCA to project the data into a lower-dimensional subspace\n",
    "    pca = PCA(n_components=n_components)\n",
    "    projected_data = pca.fit_transform(data)\n",
    "    \n",
    "    # Step 2: Calculate the mean and covariance matrix of the projected data\n",
    "    mean = np.mean(projected_data, axis=0)\n",
    "    cov_matrix = np.cov(projected_data, rowvar=False)\n",
    "    inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "    \n",
    "    # Step 3: Compute Mahalanobis distance for each point in the projected space\n",
    "    distances = np.array([mahalanobis(x, mean, inv_cov_matrix) for x in projected_data])\n",
    "    \n",
    "    # Step 4: Identify outliers based on the threshold\n",
    "    outlier_mask = distances > threshold\n",
    "    outliers = data[outlier_mask]\n",
    "    cleaned_data = data[~outlier_mask]\n",
    "    \n",
    "    num_outliers = len(outliers)\n",
    "    \n",
    "    return cleaned_data, num_outliers\n",
    "\n",
    "tr_d, num_outliers = psod_outlier_detection_removal(tr_d, n_components=2, threshold=3)\n",
    "\n",
    "# print(\"Cleaned Data:\\n\", tr_d)\n",
    "print(\"Outliers:\\n\", num_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b793b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Data Train and Test \n",
    "S = StandardScaler()\n",
    "tr_d[Num_C] = S.fit_transform(tr_d[Num_C])\n",
    "te_d[Num_C] = S.transform(te_d[Num_C])\n",
    "print_unique_header('Data Scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadfda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Target \n",
    "Le = LabelEncoder()\n",
    "tr_d['Target'] = Le.fit_transform(tr_d['Target'])\n",
    "print_unique_header('Target Encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f9139",
   "metadata": {},
   "source": [
    "# flaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f56e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initlize The autoML\n",
    "autoML = AutoML()\n",
    "# Fit autoML on Data\n",
    "autoML.fit(X_TR, Y_TR, task=\"classification\",metric='roc_auc_ovo',time_budget=3800*3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
